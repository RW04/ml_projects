{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine standing at the check-out counter at the grocery store with a long line behind you and the cashier not-so-quietly announces that your card has been declined. In this moment, you probably aren’t thinking about the data science that determined your fate.<br>\n",
    "\n",
    "Embarrassed, and certain you have the funds to cover everything needed for an epic nacho party for 50 of your closest friends, you try your card again. Same result. As you step aside and allow the cashier to tend to the next customer, you receive a text message from your bank. “Press 1 if you really tried to spend $500 on cheddar cheese.”<br>\n",
    "\n",
    "While perhaps cumbersome (and often embarrassing) in the moment, this fraud prevention system is actually saving consumers millions of dollars per year. Researchers from the IEEE Computational Intelligence Society (IEEE-CIS) want to improve this figure, while also improving the customer experience. With higher accuracy fraud detection, you can get on with your chips without the hassle.<br>\n",
    "\n",
    "The data comes from Vesta's real-world e-commerce transactions and contains a wide range of features from device type to product features. You also have the opportunity to create new features to improve your results.<br>\n",
    "\n",
    "More details on this Kaggle competition can be found [here](https://www.kaggle.com/c/ieee-fraud-detection/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are predicting the probability that an online transaction is fraudulent, as denoted by the binary target `isFraud`. The data is broken into two files `identity` and `transaction`, which are joined by `TransactionID`. Not all transactions have corresponding identity information.<br><br>\n",
    "\n",
    "**Transaction Table**<br>\n",
    "- TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n",
    "- TransactionAMT: transaction payment amount in USD\n",
    "- ProductCD: product code, the product for each transaction\n",
    "- card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n",
    "- addr: address\n",
    "- dist: distances between (not limited) billing address, mailing address, zip code, IP address, phone area, etc.\n",
    "- P_ and (R__) emaildomain: purchaser and recipient email domain\n",
    "- C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n",
    "- D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "- M1-M9: match, such as names on card and address, etc.\n",
    "- Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.<br><br>\n",
    "\n",
    "Categorical Features in this table\n",
    "****\n",
    "- `ProductCD`\n",
    "- `card1` - `card6`\n",
    "- `addr1` , `addr2`\n",
    "- `P_emaildomain`\n",
    "- `R_emaildomain`\n",
    "- `M1` - `M9`<br>\n",
    "\n",
    "\n",
    "\n",
    "**Identity Table**<br>\n",
    "Variables in this table are identity information – network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with transactions. They're collected by Vesta’s fraud protection system and digital security partners. (The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)<br>\n",
    "\n",
    "Categorical Features in this table\n",
    "****\n",
    "- `DeviceType`\n",
    "- `DeviceInfo`\n",
    "- `id_12` - `id_38` <br>\n",
    "\n",
    "**Files**\n",
    "\n",
    "- train_{transaction, identity}.csv - the training set\n",
    "- test_{transaction, identity}.csv - the test set (you must predict the `isFraud` value for these observations)\n",
    "- sample_submission.csv - a sample submission file in the correct format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us unzip the `ieee-fraud-detection.zip` file present in the `input` folder and move it to `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  input/ieee-fraud-detection.zip\n",
      "  inflating: data/test_identity.csv  \n",
      "  inflating: data/test_transaction.csv  \n",
      "  inflating: data/train_identity.csv  \n",
      "  inflating: data/sample_submission.csv  \n",
      "  inflating: data/train_transaction.csv  \n"
     ]
    }
   ],
   "source": [
    "#Unzipping the files\n",
    "!unzip 'input/ieee-fraud-detection.zip' -d 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test_identity.csv', 'test_transaction.csv', 'train_identity.csv', 'train_transaction.csv']\n"
     ]
    }
   ],
   "source": [
    "#Printing the contents in the data directory\n",
    "import os\n",
    "print(os.listdir(\"data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings in Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#For more info on arguments of seaborn.set()\n",
    "#https://seaborn.pydata.org/generated/seaborn.set.html\n",
    "\n",
    "#Graphics in SVG format are more sharp and legible\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "#Increase the default plot size and set the color scheme\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "#This works as well - plt.rcParams['figure.figsize'] = 8,5\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.7 s, sys: 42 s, total: 1min 26s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_transact_train = pd.read_csv('data/train_transaction.csv')\n",
    "df_id_train = pd.read_csv('data/train_identity.csv')\n",
    "df_transact_test = pd.read_csv('data/test_transaction.csv')\n",
    "df_id_test = pd.read_csv('data/test_identity.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_transact_train dataframe(590540, 394)\n",
      "Shape of df_id_train dataframe(144233, 41)\n",
      "Shape of df_transact_test dataframe(506691, 393)\n",
      "Shape of df_id_test dataframe(141907, 41)\n",
      "Shape of sample_submission dataframe(506691, 2)\n"
     ]
    }
   ],
   "source": [
    "#Printing the shapes of the dataframe(s)\n",
    "print('Shape of df_transact_train dataframe{}'.format(df_transact_train.shape))\n",
    "print('Shape of df_id_train dataframe{}'.format(df_id_train.shape))\n",
    "print('Shape of df_transact_test dataframe{}'.format(df_transact_test.shape))\n",
    "print('Shape of df_id_test dataframe{}'.format(df_id_test.shape))\n",
    "print('Shape of sample_submission dataframe{}'.format(sample_submission.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the problem statement, the data is broken into two files `identity` and `transaction`, which are joined by `TransactionID`. Not all transactions have corresponding identity information.<br>\n",
    "Since _not all transactions have corresponding identity information_ we will use a (left) outer join, using pandas `merge` function as a key might not appear in both tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging 'df_transact_train' and 'df_id_train'\n",
    "df_train = pd.merge(df_transact_train, df_id_train, how = 'left', on = 'TransactionID')\n",
    "\n",
    "#Merging 'df_transact_test' and 'df_id_test'\n",
    "df_test = pd.merge(df_transact_test, df_id_test, how = 'left', on = 'TransactionID')\n",
    "\n",
    "#Reducing the memory usage\n",
    "del df_transact_train, df_id_train, df_transact_test, df_id_test\n",
    "\n",
    "#Setting the index as 'TransactionID'\n",
    "#df_train = df_train.set_index('TransactionID', drop = 'True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset has 590540 rows and 434 columns\n",
      "Testing dataset has 506691 rows and 433 columns\n"
     ]
    }
   ],
   "source": [
    "#Print the shape of the new train and test dataframe(s)\n",
    "print(\"Training dataset has {} rows and {} columns\".format(df_train.shape[0], df_train.shape[1]))\n",
    "print(\"Testing dataset has {} rows and {} columns\".format(df_test.shape[0], df_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>samsung browser 6.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2220x1080</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ...                id_31  id_32  \\\n",
       "0    NaN  150.0    discover  142.0  ...                  NaN    NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...                  NaN    NaN   \n",
       "2  490.0  150.0        visa  166.0  ...                  NaN    NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...                  NaN    NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  samsung browser 6.2   32.0   \n",
       "\n",
       "       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  \\\n",
       "0        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "1        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "2        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "3        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "4  2220x1080  match_status:2      T     F     T      T      mobile   \n",
       "\n",
       "                      DeviceInfo  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4  SAMSUNG SM-G892A Build/NRD90M  \n",
       "\n",
       "[5 rows x 434 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying first 5 rows of df_train dataset\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>18403224</td>\n",
       "      <td>31.95</td>\n",
       "      <td>W</td>\n",
       "      <td>10409</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>18403263</td>\n",
       "      <td>49.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4272</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>18403310</td>\n",
       "      <td>171.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4476</td>\n",
       "      <td>574.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>18403310</td>\n",
       "      <td>284.95</td>\n",
       "      <td>W</td>\n",
       "      <td>10989</td>\n",
       "      <td>360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>18403317</td>\n",
       "      <td>67.95</td>\n",
       "      <td>W</td>\n",
       "      <td>18018</td>\n",
       "      <td>452.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
       "0        3663549       18403224           31.95         W  10409  111.0   \n",
       "1        3663550       18403263           49.00         W   4272  111.0   \n",
       "2        3663551       18403310          171.00         W   4476  574.0   \n",
       "3        3663552       18403310          284.95         W  10989  360.0   \n",
       "4        3663553       18403317           67.95         W  18018  452.0   \n",
       "\n",
       "   card3       card4  card5  card6  ...  id_31  id_32  id_33  id_34 id_35  \\\n",
       "0  150.0        visa  226.0  debit  ...    NaN    NaN    NaN    NaN   NaN   \n",
       "1  150.0        visa  226.0  debit  ...    NaN    NaN    NaN    NaN   NaN   \n",
       "2  150.0        visa  226.0  debit  ...    NaN    NaN    NaN    NaN   NaN   \n",
       "3  150.0        visa  166.0  debit  ...    NaN    NaN    NaN    NaN   NaN   \n",
       "4  150.0  mastercard  117.0  debit  ...    NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "  id_36  id_37  id_38  DeviceType  DeviceInfo  \n",
       "0   NaN    NaN    NaN         NaN         NaN  \n",
       "1   NaN    NaN    NaN         NaN         NaN  \n",
       "2   NaN    NaN    NaN         NaN         NaN  \n",
       "3   NaN    NaN    NaN         NaN         NaN  \n",
       "4   NaN    NaN    NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 433 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying first 5 rows of df_test dataset\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 590540 entries, 0 to 590539\n",
      "Columns: 434 entries, TransactionID to DeviceInfo\n",
      "dtypes: float64(399), int64(4), object(31)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 506691 entries, 0 to 506690\n",
      "Columns: 433 entries, TransactionID to DeviceInfo\n",
      "dtypes: float64(399), int64(3), object(31)\n",
      "memory usage: 1.6+ GB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_train` has 434 columns(features), out of which 399 are `float`, 4 are `int64` and 31 are `object` datatypes.<br>\n",
    "`df_test` has 433 columns(features), out of which 399 are `float`, 3 are `int64` and 31 are `object` datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are so many features in both train and test dataset(s), `df.columns` will not list all the features. In order to list all the features, we need to take the help of indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to display all the columns\n",
    "def list_of_entire_features(df):\n",
    "    first_set_of_100_features = df.columns[0:100]\n",
    "    second_set_of_100_features = df.columns[101:200]\n",
    "    third_set_of_100_features = df.columns[201:300]\n",
    "    fourth_set_of_100_features = df.columns[301:400]\n",
    "    rem_features = df.columns[401:]\n",
    "    return first_set_of_100_features, second_set_of_100_features, third_set_of_100_features, fourth_set_of_100_features, rem_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
       "        'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
       "        'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain',\n",
       "        'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n",
       "        'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8',\n",
       "        'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4',\n",
       "        'M5', 'M6', 'M7', 'M8', 'M9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7',\n",
       "        'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17',\n",
       "        'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27',\n",
       "        'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37',\n",
       "        'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45'],\n",
       "       dtype='object'),\n",
       " Index(['V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56',\n",
       "        'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66',\n",
       "        'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76',\n",
       "        'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86',\n",
       "        'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96',\n",
       "        'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105',\n",
       "        'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114',\n",
       "        'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123',\n",
       "        'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132',\n",
       "        'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141',\n",
       "        'V142', 'V143', 'V144', 'V145'],\n",
       "       dtype='object'),\n",
       " Index(['V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155',\n",
       "        'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164',\n",
       "        'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173',\n",
       "        'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182',\n",
       "        'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191',\n",
       "        'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200',\n",
       "        'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209',\n",
       "        'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218',\n",
       "        'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227',\n",
       "        'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236',\n",
       "        'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245'],\n",
       "       dtype='object'),\n",
       " Index(['V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255',\n",
       "        'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264',\n",
       "        'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273',\n",
       "        'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282',\n",
       "        'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291',\n",
       "        'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300',\n",
       "        'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309',\n",
       "        'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318',\n",
       "        'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327',\n",
       "        'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336',\n",
       "        'V337', 'V338', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05',\n",
       "        'id_06'],\n",
       "       dtype='object'),\n",
       " Index(['id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15',\n",
       "        'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23',\n",
       "        'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31',\n",
       "        'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
       "        'DeviceType', 'DeviceInfo'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the features of training dataset\n",
    "list_of_entire_features(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['TransactionID', 'TransactionDT', 'TransactionAmt', 'ProductCD',\n",
       "        'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2',\n",
       "        'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C3',\n",
       "        'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14',\n",
       "        'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11',\n",
       "        'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7',\n",
       "        'M8', 'M9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "        'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "        'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30',\n",
       "        'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40',\n",
       "        'V41', 'V42', 'V43', 'V44', 'V45', 'V46'],\n",
       "       dtype='object'),\n",
       " Index(['V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57',\n",
       "        'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67',\n",
       "        'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77',\n",
       "        'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87',\n",
       "        'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97',\n",
       "        'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106',\n",
       "        'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115',\n",
       "        'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124',\n",
       "        'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133',\n",
       "        'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142',\n",
       "        'V143', 'V144', 'V145', 'V146'],\n",
       "       dtype='object'),\n",
       " Index(['V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156',\n",
       "        'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165',\n",
       "        'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174',\n",
       "        'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183',\n",
       "        'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192',\n",
       "        'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201',\n",
       "        'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210',\n",
       "        'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219',\n",
       "        'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228',\n",
       "        'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237',\n",
       "        'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246'],\n",
       "       dtype='object'),\n",
       " Index(['V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256',\n",
       "        'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265',\n",
       "        'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274',\n",
       "        'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283',\n",
       "        'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292',\n",
       "        'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301',\n",
       "        'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310',\n",
       "        'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319',\n",
       "        'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328',\n",
       "        'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337',\n",
       "        'V338', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06',\n",
       "        'id_07'],\n",
       "       dtype='object'),\n",
       " Index(['id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16',\n",
       "        'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24',\n",
       "        'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32',\n",
       "        'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType',\n",
       "        'DeviceInfo'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the features of test dataset\n",
    "list_of_entire_features(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data-type(s) of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the problem statement, following features are categorical,<br>\n",
    "\n",
    "_Transaction_ table - `ProductCD`, `card1` - `card6`, `addr1` , `addr2`, `P_emaildomain`, `R_emaildomain`, `M1` - `M9`<br>\n",
    "_Identity_ table - `DeviceType`, `DeviceInfo`, `id_12` - `id_38` <br>\n",
    "\n",
    "Either we can verify if this holds true for each of the above feature(s) like below (for `card1` - `card6` features) or we can convert all these features to `object` datatype irrespective of the the datatype(s) they current belong to. This can be done using `astype()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID    590540\n",
       "isFraud               2\n",
       "TransactionDT    573349\n",
       "card1             13553\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of features having dtype = int64 in df_train\n",
    "df_train.select_dtypes(include='int64').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductCD           5\n",
       "card4               4\n",
       "card6               4\n",
       "P_emaildomain      59\n",
       "R_emaildomain      60\n",
       "M1                  2\n",
       "M2                  2\n",
       "M3                  2\n",
       "M4                  3\n",
       "M5                  2\n",
       "M6                  2\n",
       "M7                  2\n",
       "M8                  2\n",
       "M9                  2\n",
       "id_12               2\n",
       "id_15               3\n",
       "id_16               2\n",
       "id_23               3\n",
       "id_27               2\n",
       "id_28               2\n",
       "id_29               2\n",
       "id_30              75\n",
       "id_31             130\n",
       "id_33             260\n",
       "id_34               4\n",
       "id_35               2\n",
       "id_36               2\n",
       "id_37               2\n",
       "id_38               2\n",
       "DeviceType          2\n",
       "DeviceInfo       1786\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Number of features having dtype = object in df_train\n",
    "df_train.select_dtypes(include = np.object).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 590540 entries, 0 to 590539\n",
      "Data columns (total 6 columns):\n",
      "card1    590540 non-null int64\n",
      "card2    581607 non-null float64\n",
      "card3    588975 non-null float64\n",
      "card4    588963 non-null object\n",
      "card5    586281 non-null float64\n",
      "card6    588969 non-null object\n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 31.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train[[x for x in df_train if 'card' in x]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert features datatype\n",
    "def convert_datatype(df):\n",
    "    \n",
    "    card_cols = [x for x in df.columns if 'card' in x]\n",
    "    for col in card_cols:\n",
    "        df[card_cols] = df[card_cols].astype('object')\n",
    "    \n",
    "    addr_cols = [x for x in df.columns if 'addr' in x]\n",
    "    for col in addr_cols:\n",
    "        df[addr_cols] = df[addr_cols].astype('object')\n",
    "    \n",
    "    M_cols = [x for x in df.columns if 'M' in x]\n",
    "    for col in M_cols:\n",
    "        df[M_cols] = df[M_cols].astype('object')\n",
    "    \n",
    "    id_cols = [x for x in df.columns if 'id' in x]\n",
    "    for col in id_cols:\n",
    "        df[id_cols] = df[id_cols].astype('object')\n",
    "    \n",
    "    df['P_emaildomain'] = df['P_emaildomain'].astype('object')\n",
    "    df['R_emaildomain'] = df['R_emaildomain'].astype('object')\n",
    "    df['DeviceType'] = df['DeviceType'].astype('object')\n",
    "    df['DeviceInfo'] = df['DeviceInfo'].astype('object')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the above function to 'df_train' and 'df_test'\n",
    "\n",
    "#Try to use tqdm here LATER!!!\n",
    "df_train = convert_datatype(df_train)\n",
    "df_test = convert_datatype(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 590540 entries, 0 to 590539\n",
      "Columns: 434 entries, TransactionID to DeviceInfo\n",
      "dtypes: float64(371), int64(3), object(60)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 506691 entries, 0 to 506690\n",
      "Columns: 433 entries, TransactionID to DeviceInfo\n",
      "dtypes: float64(371), int64(2), object(60)\n",
      "memory usage: 1.6+ GB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the count of features having `object` datatype has increased in both training and test dataset(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset contains many features, to find any pattern it's essential to divide the dataframe into sub-dataframe(s) meaning creating new dataframe(s) consisting of related feature(s).<br>\n",
    "We already have seen there are many `NaN` values, what we should do next is investigate if there are missing observations for some columns that are marked as a `zero value`. We can verify this by the definition of those columns and the domain knowledge that a zero value is invalid for those measures, e.g. a zero for email_columns(as initialized below) is invalid.<br>\n",
    "In order to do the same, we can use `df.describe()` to print summary statistics on each attribute, focus on the `min` value for each of them and see for ourselves whether there can actually be a minimum value of `zero` for that attribute or if it is because of presence of null-values.<br>\n",
    "But since, this dataset doesn't contain any `zero` values for null values, we will skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since 'TransactionID' is just ID we will exclude that feature since there is no meaningful statistic to infer from it\n",
    "\n",
    "#Setting the feature(s) list for `df_train` dataset\n",
    "useful_columns_train = ['isFraud', 'TransactionDT', 'TransactionAmt', 'ProductCD']\n",
    "card_columns_train = [x for x in df_train.columns if 'card' in x]\n",
    "addr_columns_train = [x for x in df_train.columns if 'addr' in x]\n",
    "dist_columns = ['dist1', 'dist2']\n",
    "email_columns = ['P_emaildomain', 'R_emaildomain']\n",
    "C_columns = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14']\n",
    "D_columns = ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14']\n",
    "M_columns_train = [x for x in df_train.columns if 'M' in x]\n",
    "V_columns_train = [x for x in df_train.columns if 'V' in x]\n",
    "id_columns_train = [x for x in df_train.columns if 'id' in x]\n",
    "device_columns = ['DeviceType', 'DeviceInfo']\n",
    "\n",
    "#Setting the feature(s) list for `df_test` dataset\n",
    "useful_columns_train = ['isFraud', 'TransactionDT', 'TransactionAmt', 'ProductCD']\n",
    "card_columns_test = [x for x in df_test.columns if 'card' in x]\n",
    "addr_columns_test = [x for x in df_test.columns if 'addr' in x]\n",
    "dist_columns = ['dist1', 'dist2']\n",
    "email_columns = ['P_emaildomain', 'R_emaildomain']\n",
    "C_columns = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14']\n",
    "D_columns = ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14']\n",
    "M_columns_test = [x for x in df_test.columns if 'M' in x]\n",
    "V_columns_test = [x for x in df_test.columns if 'V' in x]\n",
    "id_columns_test = [x for x in df_test.columns if 'id' in x]\n",
    "device_columns = ['DeviceType', 'DeviceInfo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 414 columns in training dataset with missing values.\n",
      "There are 385 columns in testing dataset with missing values.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {df_train.isnull().any().sum()} columns in training dataset with missing values.')\n",
    "print(f'There are {df_test.isnull().any().sum()} columns in testing dataset with missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to List out the non-null features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.905400e+05</td>\n",
       "      <td>590540.000000</td>\n",
       "      <td>5.905400e+05</td>\n",
       "      <td>590540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.282270e+06</td>\n",
       "      <td>0.034990</td>\n",
       "      <td>7.372311e+06</td>\n",
       "      <td>135.027176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.704744e+05</td>\n",
       "      <td>0.183755</td>\n",
       "      <td>4.617224e+06</td>\n",
       "      <td>239.162522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.987000e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.640000e+04</td>\n",
       "      <td>0.251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.134635e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.027058e+06</td>\n",
       "      <td>43.321000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.282270e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.306528e+06</td>\n",
       "      <td>68.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.429904e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.124662e+07</td>\n",
       "      <td>125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.577539e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.581113e+07</td>\n",
       "      <td>31937.391000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TransactionID        isFraud  TransactionDT  TransactionAmt\n",
       "count   5.905400e+05  590540.000000   5.905400e+05   590540.000000\n",
       "mean    3.282270e+06       0.034990   7.372311e+06      135.027176\n",
       "std     1.704744e+05       0.183755   4.617224e+06      239.162522\n",
       "min     2.987000e+06       0.000000   8.640000e+04        0.251000\n",
       "25%     3.134635e+06       0.000000   3.027058e+06       43.321000\n",
       "50%     3.282270e+06       0.000000   7.306528e+06       68.769000\n",
       "75%     3.429904e+06       0.000000   1.124662e+07      125.000000\n",
       "max     3.577539e+06       1.000000   1.581113e+07    31937.391000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing useful stats for numerical features\n",
    "#Note: 'ProductCD' belongs to 'object' datatype and other features are 'numerical' datatype hence no output for this feature\n",
    "df_train[useful_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will either have to drop the columns having missing values or impute them. <br>\n",
    "\n",
    "**Strategy 1**\n",
    "- Drop the columns/features having more than 50% missing values as it will not be convenient to impute these values since most of the attribute values will be guessed.\n",
    "- \n",
    "\n",
    "**Strategy 2** \n",
    "\n",
    "- Impute all the NaN values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID        0\n",
       "isFraud              0\n",
       "TransactionDT        0\n",
       "TransactionAmt       0\n",
       "ProductCD            0\n",
       "card1                0\n",
       "card2             8933\n",
       "card3             1565\n",
       "card4             1577\n",
       "card5             4259\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of null values in each feature of 'df_train'\n",
    "df_train.isnull().sum()[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "#Percentage of null values in each feature of 'df_train'\n",
    "df_train.isnull().sum()/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "#Number of null values in each feature of 'df_test'\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "#Percentage of null values in each feature of 'df_test'\n",
    "df_test.isnull().sum()/len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miss_values_gr_50(df):\n",
    "    missing_values = df.isnull().sum()/len(df)\n",
    "    cols_miss_values_50 = df.columns[missing_values > 0.5]\n",
    "    df = df.drop(cols_miss_values_50, axis=1)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = miss_values_gr_50(df_train)\n",
    "df_test = miss_values_gr_50(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {df_train.isnull().any().sum()} columns in training dataset with missing values.')\n",
    "print(f'There are {df_test.isnull().any().sum()} columns in testing dataset with missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "sns.heatmap(df_train, annot = True , fmt = \".01f\" , linewidths= 0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a look at `isFraud` feature in the `df_train` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlcourseai] *",
   "language": "python",
   "name": "conda-env-mlcourseai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
